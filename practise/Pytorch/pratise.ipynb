{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(55)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(55)\n",
    "scalar = torch.tensor(55)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([1, 2, 3])\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0086, 0.5538, 0.7504, 0.2091, 0.3364, 0.3801, 0.3129, 0.9591, 0.2780,\n",
       "         0.2288],\n",
       "        [0.2099, 0.5013, 0.7572, 0.9901, 0.0602, 0.9984, 0.4344, 0.6416, 0.1867,\n",
       "         0.6489],\n",
       "        [0.3554, 0.0030, 0.7150, 0.5632, 0.9989, 0.2278, 0.4122, 0.8923, 0.3545,\n",
       "         0.6787],\n",
       "        [0.8755, 0.5167, 0.6189, 0.8173, 0.6484, 0.3257, 0.6428, 0.1383, 0.4187,\n",
       "         0.2599],\n",
       "        [0.5241, 0.7239, 0.8394, 0.6891, 0.8345, 0.9628, 0.8799, 0.9766, 0.8651,\n",
       "         0.8732],\n",
       "        [0.9657, 0.0015, 0.2245, 0.5783, 0.5438, 0.3707, 0.1127, 0.4941, 0.6836,\n",
       "         0.3466],\n",
       "        [0.2495, 0.9856, 0.6186, 0.8346, 0.3417, 0.4720, 0.1286, 0.5418, 0.8394,\n",
       "         0.0201],\n",
       "        [0.3012, 0.4965, 0.7230, 0.3636, 0.2544, 0.7122, 0.5694, 0.9697, 0.2614,\n",
       "         0.5329],\n",
       "        [0.5350, 0.2124, 0.6599, 0.2933, 0.4122, 0.6820, 0.8999, 0.4708, 0.9136,\n",
       "         0.5749],\n",
       "        [0.7857, 0.6781, 0.5219, 0.3247, 0.7880, 0.7739, 0.5515, 0.0071, 0.5837,\n",
       "         0.6239],\n",
       "        [0.8605, 0.2301, 0.7846, 0.0595, 0.3604, 0.7921, 0.0035, 0.8371, 0.0628,\n",
       "         0.8890],\n",
       "        [0.9650, 0.3066, 0.6524, 0.9767, 0.5030, 0.9875, 0.1426, 0.2278, 0.6885,\n",
       "         0.2799],\n",
       "        [0.9100, 0.6395, 0.9984, 0.7274, 0.8588, 0.9732, 0.8859, 0.9545, 0.1110,\n",
       "         0.8034],\n",
       "        [0.7280, 0.3390, 0.8962, 0.3137, 0.5919, 0.8587, 0.2944, 0.7323, 0.6317,\n",
       "         0.1879],\n",
       "        [0.0765, 0.5634, 0.6819, 0.1940, 0.6900, 0.9551, 0.5836, 0.5781, 0.1567,\n",
       "         0.0761],\n",
       "        [0.7640, 0.0834, 0.0773, 0.5037, 0.1451, 0.4932, 0.3450, 0.6572, 0.9535,\n",
       "         0.5906],\n",
       "        [0.9542, 0.9230, 0.2217, 0.4156, 0.8817, 0.6880, 0.1547, 0.3093, 0.1884,\n",
       "         0.0720],\n",
       "        [0.2294, 0.4617, 0.2811, 0.0948, 0.5503, 0.9400, 0.0118, 0.9783, 0.0744,\n",
       "         0.1874],\n",
       "        [0.8761, 0.9508, 0.4643, 0.4588, 0.7830, 0.0450, 0.0787, 0.5067, 0.8164,\n",
       "         0.6328],\n",
       "        [0.0023, 0.1087, 0.6134, 0.1401, 0.8283, 0.9738, 0.8806, 0.6132, 0.2570,\n",
       "         0.9193],\n",
       "        [0.7780, 0.4892, 0.5480, 0.5617, 0.7048, 0.4668, 0.5875, 0.8869, 0.9096,\n",
       "         0.2877],\n",
       "        [0.5534, 0.6418, 0.6664, 0.9017, 0.6319, 0.1630, 0.2849, 0.4818, 0.3049,\n",
       "         0.8006],\n",
       "        [0.5634, 0.6344, 0.8882, 0.1029, 0.9553, 0.9035, 0.9765, 0.3994, 0.5969,\n",
       "         0.4124],\n",
       "        [0.2670, 0.3615, 0.3975, 0.5384, 0.5396, 0.7398, 0.3765, 0.3656, 0.9559,\n",
       "         0.5903],\n",
       "        [0.8115, 0.1683, 0.7885, 0.8540, 0.0418, 0.4125, 0.7387, 0.1527, 0.3391,\n",
       "         0.4160],\n",
       "        [0.5819, 0.1615, 0.5471, 0.9430, 0.9156, 0.8168, 0.2784, 0.9438, 0.4224,\n",
       "         0.1642],\n",
       "        [0.0557, 0.6695, 0.9128, 0.0508, 0.9260, 0.5915, 0.7701, 0.5030, 0.6985,\n",
       "         0.1800],\n",
       "        [0.7692, 0.0981, 0.9444, 0.8190, 0.3946, 0.0810, 0.4443, 0.9978, 0.7558,\n",
       "         0.3477],\n",
       "        [0.5389, 0.1496, 0.1120, 0.0214, 0.0347, 0.5737, 0.8467, 0.2509, 0.8022,\n",
       "         0.0391],\n",
       "        [0.2744, 0.9483, 0.9708, 0.3168, 0.3617, 0.3844, 0.1073, 0.5962, 0.9803,\n",
       "         0.2724]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(size=(30, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(size=(3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(size=(3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "matrix.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(2, 10).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = torch.tensor([[1.,3.,5.], [7.,9.,11.]], requires_grad=True, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = torch.tensor([[1.,3.,5.], [7.,9.,11.]])\n",
    "vector2 = torch.tensor([[1.,3.,5.], [7.,9.,11.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x3 and 2x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x3 and 2x3)"
     ]
    }
   ],
   "source": [
    "torch.matmul(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(11.), tensor(1.), tensor([2, 2]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1.max(), vector2.min(), vector.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(2))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = vector.argmax()\n",
    "torch.unravel_index(index, vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  3.,  5.],\n",
       "        [ 7.,  9., 11.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  3.,  5.],\n",
       "         [ 7.,  9., 11.]],\n",
       "\n",
       "        [[ 1.,  3.,  5.],\n",
       "         [ 7.,  9., 11.]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((vector1, vector2), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  3.,  5.],\n",
       "         [ 1.,  3.,  5.]],\n",
       "\n",
       "        [[ 7.,  9., 11.],\n",
       "         [ 7.,  9., 11.]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((vector1, vector2), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional  as F\n",
    "\n",
    "class IrisClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(4, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 4)\n",
    "        output = F.relu(self.linear(x), inplace=True)\n",
    "        return output\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "model = IrisClassification().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight', tensor([[-0.3649,  0.0150,  0.1911, -0.1114]])),\n",
       "             ('linear.bias', tensor([-0.3005]))])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                    [-1, 1]               5\n",
      "================================================================\n",
      "Total params: 5\n",
      "Trainable params: 5\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "model.train()\n",
    "num_epoch = 10\n",
    "running_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "for epoch in range(1, num_epoch+1):\n",
    "    \n",
    "    #FP\n",
    "    prediction = model(x)\n",
    "    loss = criterion(prediction, y)\n",
    "\n",
    "    # BP\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Metrics\n",
    "    running_loss += loss*x.size(0)\n",
    "    _, predicted_class = prediction.max(1)\n",
    "    correct += predicted_class.eq(x).sum().item()\n",
    "    total += x.size(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Conv2d(3, 64, 7, stride=2),\n",
    "        nn.BatchNorm2d((1,1)),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(64, 64, 3),\n",
    "        nn.BatchNorm2d((1,1)),\n",
    "        nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[-4.8642e-02,  6.9436e-04, -5.9131e-02,  ...,  3.0764e-02,\n",
      "            1.3112e-02, -3.8074e-02],\n",
      "          [-6.4995e-02, -1.9950e-03, -6.2453e-02,  ...,  6.9200e-02,\n",
      "            4.6936e-02, -2.1371e-02],\n",
      "          [-4.4116e-03, -5.1812e-02,  3.2731e-02,  ...,  1.5321e-02,\n",
      "           -2.4859e-02,  5.3121e-02],\n",
      "          ...,\n",
      "          [ 4.5806e-02, -5.0397e-02,  3.7417e-02,  ...,  6.8711e-02,\n",
      "            1.1926e-02, -3.0256e-02],\n",
      "          [-3.9526e-02,  6.3543e-02,  3.0541e-02,  ...,  3.8710e-02,\n",
      "           -3.7262e-02,  6.7446e-03],\n",
      "          [ 8.1409e-02,  1.5275e-02,  8.0501e-03,  ...,  2.8322e-02,\n",
      "           -6.4198e-02, -5.3588e-02]],\n",
      "\n",
      "         [[-3.0905e-02, -4.7240e-02, -3.1640e-02,  ..., -6.2007e-02,\n",
      "            2.8818e-02, -2.9639e-02],\n",
      "          [ 2.1910e-02,  3.4598e-02,  2.3780e-02,  ...,  3.3503e-02,\n",
      "            3.4600e-02,  6.5620e-02],\n",
      "          [ 7.0242e-02,  2.9624e-02,  6.7898e-02,  ..., -1.6024e-02,\n",
      "            2.1230e-02, -3.6179e-02],\n",
      "          ...,\n",
      "          [ 5.1252e-02, -5.9819e-02, -2.0789e-02,  ...,  1.3982e-02,\n",
      "            3.2348e-02,  8.1456e-02],\n",
      "          [ 6.8597e-02,  8.0309e-02, -3.0763e-02,  ..., -5.8757e-02,\n",
      "            6.7878e-03, -6.0339e-02],\n",
      "          [-3.4641e-02,  1.7148e-02,  4.8860e-02,  ..., -1.0707e-02,\n",
      "            7.7527e-02,  1.5502e-03]],\n",
      "\n",
      "         [[ 6.4915e-02,  4.5959e-02,  6.0005e-02,  ..., -3.3126e-02,\n",
      "           -5.1593e-03, -4.7595e-03],\n",
      "          [-1.2356e-02,  3.6025e-02, -1.8227e-02,  ..., -2.1199e-02,\n",
      "           -6.6252e-02, -2.0804e-02],\n",
      "          [ 1.6462e-02, -2.9946e-02, -2.0634e-02,  ...,  7.6351e-02,\n",
      "            7.1762e-02, -3.3248e-02],\n",
      "          ...,\n",
      "          [-7.1267e-02, -4.7816e-02, -5.7002e-02,  ...,  1.1012e-02,\n",
      "           -4.3020e-02, -6.6535e-02],\n",
      "          [-7.1153e-02,  6.8136e-02, -6.8636e-02,  ..., -2.3974e-02,\n",
      "           -7.7900e-02,  3.9102e-02],\n",
      "          [ 5.6122e-02, -1.7732e-02, -2.8550e-02,  ..., -2.1510e-02,\n",
      "            3.2534e-02,  2.9208e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.5677e-02,  7.8417e-02,  5.0797e-03,  ..., -4.6279e-03,\n",
      "            8.0482e-02,  5.3201e-02],\n",
      "          [-6.7949e-02, -4.5982e-02,  3.6011e-03,  ...,  2.7979e-02,\n",
      "            3.4204e-02, -3.9665e-02],\n",
      "          [-7.3198e-02,  6.5174e-02, -7.3392e-02,  ..., -6.2897e-02,\n",
      "            5.8616e-02, -6.7311e-02],\n",
      "          ...,\n",
      "          [-6.4010e-02, -1.1470e-02,  3.6894e-03,  ..., -7.9851e-02,\n",
      "            8.0086e-02, -6.7802e-02],\n",
      "          [ 2.9162e-03,  3.9982e-02, -3.0030e-02,  ...,  2.2284e-02,\n",
      "            3.8784e-02, -5.0366e-02],\n",
      "          [-3.8819e-02,  2.7836e-02,  3.1651e-02,  ...,  1.8978e-02,\n",
      "           -5.9296e-02,  1.0709e-02]],\n",
      "\n",
      "         [[-4.7384e-02,  1.0893e-03, -6.7819e-02,  ..., -5.6450e-02,\n",
      "            5.6543e-02,  5.7443e-02],\n",
      "          [ 1.3430e-02,  8.0110e-03,  7.2387e-02,  ...,  4.4537e-02,\n",
      "            5.6378e-02, -7.8126e-02],\n",
      "          [ 1.2779e-02, -6.5019e-02, -5.1875e-02,  ..., -1.1845e-02,\n",
      "            2.7814e-02, -5.7698e-02],\n",
      "          ...,\n",
      "          [-7.9671e-02,  1.1153e-02,  8.4467e-03,  ...,  5.4692e-02,\n",
      "            1.2516e-03,  7.2582e-02],\n",
      "          [ 5.3284e-02, -5.6540e-02,  3.4885e-02,  ...,  4.4672e-02,\n",
      "           -7.0784e-02,  7.8734e-02],\n",
      "          [-8.0029e-02,  6.9248e-02, -3.0256e-02,  ..., -4.2065e-02,\n",
      "           -5.0182e-02, -4.9798e-03]],\n",
      "\n",
      "         [[-6.8433e-02, -5.1936e-02, -9.1816e-03,  ...,  2.3887e-02,\n",
      "           -2.5366e-02, -6.1219e-02],\n",
      "          [-1.4979e-02,  6.8766e-02, -4.4864e-03,  ..., -2.0379e-02,\n",
      "           -6.0634e-04,  1.1894e-02],\n",
      "          [ 2.8869e-02,  6.6787e-02,  3.7668e-02,  ..., -3.2840e-03,\n",
      "           -1.1183e-02, -1.9914e-02],\n",
      "          ...,\n",
      "          [-6.5086e-03, -7.5682e-02,  2.7016e-03,  ..., -5.7957e-03,\n",
      "            4.3018e-03,  5.2493e-02],\n",
      "          [-2.9262e-02, -7.7852e-02,  4.1427e-02,  ..., -6.0345e-02,\n",
      "            9.2812e-03,  3.8604e-02],\n",
      "          [ 2.1254e-02,  5.5367e-02,  2.4589e-02,  ...,  7.0061e-02,\n",
      "            9.9117e-03,  7.5559e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0744e-02, -1.7388e-02,  5.4379e-02,  ...,  7.5524e-02,\n",
      "            8.8386e-03,  4.5322e-02],\n",
      "          [-6.0121e-02, -4.8144e-02,  2.2772e-02,  ..., -6.1327e-02,\n",
      "            7.2870e-02, -1.3321e-02],\n",
      "          [ 2.1141e-03,  4.0597e-02,  4.6209e-02,  ...,  7.3781e-02,\n",
      "            6.3219e-02,  7.7916e-02],\n",
      "          ...,\n",
      "          [-2.5622e-02, -4.9748e-02, -1.8536e-02,  ..., -4.7615e-02,\n",
      "            5.5682e-02, -1.5213e-02],\n",
      "          [-6.2567e-03,  2.5399e-02, -7.8587e-02,  ..., -8.7783e-03,\n",
      "           -3.9289e-02,  3.2984e-02],\n",
      "          [-5.2335e-02,  6.0005e-02, -5.6334e-02,  ...,  2.5077e-02,\n",
      "           -6.5012e-02, -8.2721e-03]],\n",
      "\n",
      "         [[ 6.7456e-02, -3.8595e-02,  2.3808e-02,  ...,  3.9468e-02,\n",
      "            7.0867e-02,  2.5995e-02],\n",
      "          [ 2.7846e-02, -2.5012e-02, -7.1762e-02,  ..., -7.8260e-02,\n",
      "            5.7017e-02, -2.3694e-02],\n",
      "          [ 2.2258e-02, -8.0612e-02, -5.7272e-02,  ..., -3.2520e-02,\n",
      "            4.4854e-02,  5.2406e-04],\n",
      "          ...,\n",
      "          [-5.6908e-02,  7.0154e-02, -4.1826e-02,  ...,  1.0780e-02,\n",
      "           -3.2412e-02,  2.0882e-02],\n",
      "          [ 2.6500e-02,  7.0888e-02, -7.4606e-02,  ...,  3.1184e-02,\n",
      "            5.4408e-02,  1.2127e-02],\n",
      "          [ 4.3830e-02,  9.1363e-03, -9.8869e-03,  ...,  3.1886e-02,\n",
      "           -1.5867e-02, -1.3109e-02]],\n",
      "\n",
      "         [[-7.1278e-02, -6.5548e-02,  4.3192e-03,  ..., -5.5702e-02,\n",
      "           -6.9765e-03, -4.5322e-03],\n",
      "          [-6.1685e-02, -6.5338e-02, -2.4368e-02,  ...,  5.8443e-02,\n",
      "            7.2771e-02, -2.0558e-02],\n",
      "          [-4.7729e-02,  5.9214e-02, -3.1571e-02,  ...,  4.9681e-02,\n",
      "           -6.0308e-02, -5.2985e-02],\n",
      "          ...,\n",
      "          [ 4.7447e-02,  8.2087e-02,  5.7958e-02,  ...,  4.1320e-02,\n",
      "            1.7399e-02, -3.5637e-02],\n",
      "          [ 1.4683e-02,  1.9540e-03,  6.9780e-02,  ..., -1.7220e-02,\n",
      "           -6.3404e-02, -1.6090e-02],\n",
      "          [-2.2630e-02, -4.7947e-02, -4.9422e-02,  ..., -2.8685e-02,\n",
      "            1.8907e-02,  1.4676e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 7.7177e-02,  3.7024e-02, -8.2065e-02,  ...,  6.7111e-02,\n",
      "           -4.8068e-03,  1.4956e-02],\n",
      "          [-2.7416e-02,  3.2233e-02, -5.9451e-02,  ...,  3.1244e-02,\n",
      "           -4.4691e-03,  5.6476e-02],\n",
      "          [ 4.0701e-02, -6.9353e-02, -2.8048e-02,  ..., -2.5638e-02,\n",
      "            9.3513e-03,  4.1215e-02],\n",
      "          ...,\n",
      "          [ 7.3812e-03, -3.6173e-02, -4.9671e-02,  ...,  6.5459e-02,\n",
      "           -8.0981e-02, -1.3583e-02],\n",
      "          [-1.9620e-02, -6.6981e-02,  3.4196e-03,  ..., -6.2417e-02,\n",
      "           -4.4528e-03, -7.2338e-05],\n",
      "          [ 2.1216e-02,  8.2660e-03, -7.2335e-02,  ..., -3.8901e-02,\n",
      "            5.3202e-02, -6.3544e-02]],\n",
      "\n",
      "         [[ 2.8002e-02, -5.9903e-02, -2.4981e-02,  ...,  6.5313e-02,\n",
      "           -2.1049e-02, -3.8504e-02],\n",
      "          [ 7.7051e-02, -5.5738e-02,  4.7803e-02,  ...,  1.1243e-02,\n",
      "           -8.0708e-02,  1.3404e-02],\n",
      "          [ 2.9282e-03, -7.3331e-03, -7.4542e-02,  ..., -5.0526e-02,\n",
      "            4.0160e-03,  4.4233e-02],\n",
      "          ...,\n",
      "          [ 3.3993e-02,  3.4448e-02, -1.4391e-02,  ..., -1.5431e-02,\n",
      "           -1.8137e-02,  4.0121e-02],\n",
      "          [ 2.7450e-02,  3.4590e-02, -6.1764e-02,  ..., -3.5310e-02,\n",
      "            7.2148e-02,  6.2660e-02],\n",
      "          [ 9.6408e-03, -1.2432e-03,  4.1523e-02,  ...,  3.5953e-02,\n",
      "           -6.2782e-02,  5.7007e-02]],\n",
      "\n",
      "         [[-4.7695e-02, -2.5676e-03,  7.8384e-02,  ..., -1.3513e-02,\n",
      "            1.1538e-02,  4.8792e-02],\n",
      "          [-5.8267e-02,  4.2997e-04, -1.2927e-02,  ...,  3.6457e-02,\n",
      "           -1.3958e-02,  3.4439e-02],\n",
      "          [-5.3883e-02, -3.4063e-03, -5.8127e-02,  ..., -1.6635e-02,\n",
      "           -8.2144e-02,  1.5545e-02],\n",
      "          ...,\n",
      "          [-1.1859e-02,  2.8582e-02, -4.5402e-02,  ..., -7.8903e-02,\n",
      "            7.4195e-02,  2.0664e-02],\n",
      "          [-1.5352e-02,  5.1466e-02,  7.7417e-02,  ...,  5.2717e-02,\n",
      "            3.3888e-02, -3.1669e-02],\n",
      "          [-8.0460e-02, -2.6928e-02, -2.5060e-03,  ..., -4.4509e-02,\n",
      "           -2.7442e-02,  2.5252e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2325e-02, -4.9813e-02,  5.0605e-02,  ...,  5.1092e-03,\n",
      "            7.6115e-02, -9.9798e-04],\n",
      "          [ 1.5376e-02, -5.4692e-02, -3.5238e-02,  ...,  1.8115e-02,\n",
      "            4.4206e-03, -1.6575e-02],\n",
      "          [ 7.4253e-02, -4.4312e-02,  7.7616e-02,  ..., -6.0995e-03,\n",
      "            2.4521e-02, -5.3447e-02],\n",
      "          ...,\n",
      "          [ 5.7149e-02,  4.4834e-02,  4.0983e-02,  ...,  3.8026e-02,\n",
      "           -7.1788e-02, -3.2510e-02],\n",
      "          [ 6.7324e-02, -2.5307e-02, -5.8943e-02,  ..., -6.9201e-02,\n",
      "           -2.3379e-02,  1.8672e-03],\n",
      "          [-6.4312e-02,  5.1824e-02, -3.2590e-03,  ..., -4.5892e-02,\n",
      "           -5.5515e-02,  5.7653e-02]],\n",
      "\n",
      "         [[ 4.3721e-02,  7.6783e-02,  7.1008e-02,  ..., -1.8680e-03,\n",
      "           -7.4668e-02, -6.8177e-02],\n",
      "          [-2.2285e-02, -2.9557e-02, -5.3885e-02,  ...,  4.1053e-02,\n",
      "            8.2139e-02, -8.0661e-02],\n",
      "          [ 2.9586e-02, -7.3936e-02,  1.5250e-02,  ...,  3.3453e-02,\n",
      "           -5.1236e-02,  7.8330e-03],\n",
      "          ...,\n",
      "          [-3.7197e-02,  5.3156e-02, -7.1154e-02,  ...,  6.2860e-02,\n",
      "           -4.4556e-02, -7.8169e-02],\n",
      "          [ 6.0509e-02,  6.6513e-02,  5.7576e-02,  ...,  7.4516e-02,\n",
      "            1.1478e-02,  8.0471e-02],\n",
      "          [ 6.8066e-02, -3.4254e-02, -3.2974e-02,  ...,  3.7846e-02,\n",
      "            3.8096e-02, -4.5510e-02]],\n",
      "\n",
      "         [[ 6.1995e-02,  2.0984e-02,  1.0353e-02,  ...,  6.8361e-03,\n",
      "           -6.9713e-02,  4.4147e-02],\n",
      "          [-5.5768e-02, -4.9549e-02,  6.3033e-02,  ..., -8.1143e-02,\n",
      "           -8.0196e-02, -7.2537e-02],\n",
      "          [ 3.3615e-02,  2.5548e-02, -7.9627e-02,  ...,  5.6841e-02,\n",
      "           -9.2440e-03,  3.1508e-02],\n",
      "          ...,\n",
      "          [-6.2134e-02, -2.2773e-02,  3.5855e-02,  ..., -3.4085e-03,\n",
      "            5.2588e-02, -2.3629e-02],\n",
      "          [-7.1375e-02, -8.4842e-03,  4.5184e-02,  ..., -4.5640e-02,\n",
      "           -3.2245e-02,  8.5395e-03],\n",
      "          [ 1.3795e-02, -3.3065e-02,  8.2367e-02,  ...,  7.5554e-02,\n",
      "           -6.8756e-02,  7.5898e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.2753e-03,  3.6086e-02, -4.1611e-02,  ..., -6.6161e-04,\n",
      "           -5.5794e-02, -7.9787e-02],\n",
      "          [-2.3794e-03,  8.0648e-02,  4.3844e-02,  ...,  3.7627e-03,\n",
      "           -6.0447e-02,  2.7583e-02],\n",
      "          [-1.3716e-02, -4.6221e-02, -5.5640e-02,  ...,  6.1892e-02,\n",
      "            6.0278e-02,  8.1738e-03],\n",
      "          ...,\n",
      "          [-5.4530e-02,  6.9205e-02, -1.1565e-04,  ...,  6.9123e-02,\n",
      "            2.8573e-02,  5.4596e-02],\n",
      "          [ 2.6652e-02, -5.4560e-02,  1.5195e-02,  ..., -2.8532e-02,\n",
      "            4.3081e-02, -1.1855e-02],\n",
      "          [ 6.4809e-02, -7.8322e-02,  1.6214e-02,  ..., -5.4108e-02,\n",
      "           -5.5285e-02,  4.4071e-02]],\n",
      "\n",
      "         [[-6.3618e-02, -5.8677e-02, -4.9108e-02,  ..., -2.3301e-02,\n",
      "           -1.1925e-04, -7.4440e-02],\n",
      "          [-3.6775e-02, -5.7909e-02, -4.2977e-02,  ..., -6.8363e-02,\n",
      "            4.1325e-02,  1.7023e-02],\n",
      "          [ 1.2749e-02, -5.9699e-02,  5.6201e-02,  ...,  1.7360e-02,\n",
      "           -1.0912e-02,  4.7801e-02],\n",
      "          ...,\n",
      "          [ 6.0606e-02,  4.7686e-02, -5.6890e-03,  ...,  2.1337e-02,\n",
      "            2.5743e-02, -2.8690e-02],\n",
      "          [-7.4923e-02,  3.9879e-02, -1.9257e-02,  ..., -2.9006e-02,\n",
      "            9.9733e-03, -1.4249e-03],\n",
      "          [-4.6540e-02, -5.8013e-02, -1.4199e-02,  ..., -4.1337e-02,\n",
      "           -1.4725e-02, -6.1110e-02]],\n",
      "\n",
      "         [[-5.0073e-03, -4.6124e-02, -4.0842e-02,  ...,  2.5808e-02,\n",
      "            2.7117e-02,  7.4025e-02],\n",
      "          [-4.6867e-02,  6.7041e-02,  4.8761e-02,  ..., -3.9660e-02,\n",
      "            1.5437e-02, -5.2806e-02],\n",
      "          [-2.1090e-02, -6.1914e-02,  2.3312e-02,  ..., -7.9603e-02,\n",
      "           -6.7852e-02, -4.9405e-02],\n",
      "          ...,\n",
      "          [-1.6512e-03, -4.4922e-02, -8.0360e-02,  ..., -7.1494e-02,\n",
      "           -2.4505e-02, -2.3020e-02],\n",
      "          [ 3.9867e-02, -2.2231e-02, -2.6554e-02,  ..., -8.2133e-02,\n",
      "            4.1693e-02, -3.7096e-02],\n",
      "          [ 3.3882e-02,  3.9915e-02,  7.0187e-02,  ..., -6.6393e-02,\n",
      "            3.0139e-02, -6.1916e-02]]]], requires_grad=True)\n",
      "\n",
      "\n",
      "Parameter containing:\n",
      "tensor([ 0.0810,  0.0036,  0.0192,  0.0292, -0.0536,  0.0269,  0.0459, -0.0537,\n",
      "        -0.0524,  0.0165, -0.0575,  0.0351,  0.0097,  0.0043,  0.0168, -0.0207,\n",
      "        -0.0701, -0.0671,  0.0539,  0.0580,  0.0616,  0.0352,  0.0343, -0.0253,\n",
      "        -0.0352, -0.0380,  0.0240,  0.0671, -0.0685,  0.0511, -0.0591, -0.0349,\n",
      "         0.0238, -0.0189,  0.0109, -0.0170,  0.0419, -0.0335,  0.0377, -0.0729,\n",
      "        -0.0526,  0.0341, -0.0083,  0.0139, -0.0371,  0.0660, -0.0432, -0.0565,\n",
      "        -0.0400,  0.0308, -0.0690, -0.0031, -0.0536,  0.0652,  0.0816, -0.0272,\n",
      "         0.0668, -0.0644,  0.0252,  0.0727,  0.0647,  0.0568,  0.0176, -0.0694],\n",
      "       requires_grad=True)\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Conv2d' object has no attribute 'trainable'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(layer\u001b[38;5;241m.\u001b[39mbias)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable\u001b[49m)\n",
      "File \u001b[1;32md:\\SW\\anaconda3\\envs\\CV_krish\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1933\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Conv2d' object has no attribute 'trainable'"
     ]
    }
   ],
   "source": [
    "for layer in model:\n",
    "    if hasattr(layer, \"weight\") and layer.weight is not None:\n",
    "        print(layer.weight)\n",
    "        print(\"\\n\")\n",
    "    if hasattr(layer, \"bias\") and layer.bias is not None:\n",
    "        print(layer.bias)\n",
    "        print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV_krish",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
